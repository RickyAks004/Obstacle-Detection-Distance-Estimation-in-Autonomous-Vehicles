# ğŸ“Œ Obstacle Detection & Monocular Depth Estimation in Autonomous Vehicles
Monocular obstacle detection and depth estimation using YOLOv8 and Apple's Depth-Pro on the KITTI autonomous driving dataset.

YOLOv8 + Depth-Pro | KITTI Dataset | Single RGB Camera

ğŸš€ Overview

This project implements a real-time obstacle detection and distance estimation system using only a single RGB camera, without relying on stereo vision or dedicated depth sensors.
It combines:

* YOLOv8 for object detection
* Appleâ€™s Depth-Pro for monocular depth estimation
* KITTI Dataset for autonomous driving benchmarking

**This lightweight pipeline is suitable for EV perception, robotics navigation, ADAS, and assistive systems.**

**ğŸ§  Core Features**

- Single-camera obstacle perceptionâ€”no stereo vision or LiDAR required
- YOLOv8-based object detection with high accuracy and real-time performance
- Depth-Pro monocular depth estimation to approximate object distance
- KITTI dataset integration for training & evaluation
- Detectionâ€“Depth fusion to estimate per-object distance from camera view
- Modular & extensible Python codebase using PyTorch and Ultralytics

**ğŸ—‚ï¸ Project Structure**

_ğŸ“¦ obstacle-detection-depth-estimation_
 â”£ ğŸ“ models/           # YOLOv8 + Depth-Pro loading and utilities
 
 â”£ ğŸ“ data/             # KITTI dataset preprocessing scripts
 
 â”£ ğŸ“ utils/            # Visualization, depth processing, fusion modules
 
 â”£ ğŸ“ results/          # Sample outputs, predictions, heatmaps
 
 â”£ ğŸ“œ inference.py      # Run detection + depth estimation on images/videos
 
 â”£ ğŸ“œ train.py          # Optional re-training code for YOLOv8
 
 â”— ğŸ“œ README.md

 

**ğŸ“Š Dataset â€“ KITTI**

The KITTI Vision Benchmark Suite is used, containing:

- Road scenes from autonomous driving
- RGB images with calibration data
- Real-world obstacles: cars, pedestrians, cyclists
  
This ensures the pipeline generalizes well to EV and robotics environments.

**ğŸ–¼ï¸ Sample Outputs**

    [ Detection ] â†’ [ Depth Map ] â†’ [ Distance Estimation ]

**â–¶ï¸ How to Run**

1ï¸âƒ£ Clone the repository

    git clone https://github.com/yourusername/your-repo.git
    cd your-repo

2ï¸âƒ£ Install requirements

    pip install -r requirements.txt

3ï¸âƒ£ Run detection + depth estimation

    python inference.py --source sample_video.mp4

**âš™ï¸ Technologies Used**

* YOLOv8 (Ultralytics) â€“ Object Detection
* Depth-Pro (Apple) â€“ Monocular Depth Estimation
* PyTorch â€“ Model Processing
* OpenCV â€“ Visualization & Video Processing
* KITTI Dataset â€“ Benchmark Dataset

**ğŸ§© Applications**

* ğŸŸ¢ Autonomous Electric Vehicles
* ğŸŸ¢ Autonomous Mobile Robots
* ğŸŸ¢ ADAS systems
* ğŸŸ¢ Obstacle-aware navigation
* ğŸŸ¢ Assistive perception tools

**ğŸŒŸ Future Improvements**

+ Add temporal depth smoothing using optical flow
+ Integrate LiDAR-like pseudo depth for 3D point-cloud generation
+ ONNX export for edge deployment
+ ROS2 integration

ğŸ¤ Contributing

Pull requests, issue reports, and suggestions are welcome!

ğŸ“„ License

MIT License â€” feel free to use and modify.
